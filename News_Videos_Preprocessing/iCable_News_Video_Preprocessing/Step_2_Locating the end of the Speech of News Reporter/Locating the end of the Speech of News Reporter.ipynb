{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ac600f",
   "metadata": {},
   "source": [
    "# Locating the end of the News Reporter's Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4fd1f2",
   "metadata": {},
   "source": [
    "This Jupyter Notebook implements a video processing pipeline to detect semantic transition points (cut points) in videos using the CLIP (Contrastive Language-Image Pretraining) model. It processes a directory of videos, identifies the first frame where its semantic is largely different from the first frame, and saves the results to a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50512a2-73f8-4c08-bd06-586df1c3c4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos: 100%|██████████| 28899/28899 [8:08:00<00:00,  1.01s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed. Results have been saved to: ./cut_points.pkl\n",
      "      video_name  cut_frame  has_problem\n",
      "0          0.mp4        197        False\n",
      "1          1.mp4         38        False\n",
      "2       1000.mp4        359        False\n",
      "3      10001.mp4        347        False\n",
      "4      10002.mp4        143        False\n",
      "...          ...        ...          ...\n",
      "28894   9991.mp4        199        False\n",
      "28895   9992.mp4        326        False\n",
      "28896   9994.mp4        158        False\n",
      "28897   9996.mp4        132        False\n",
      "28898   9997.mp4        296        False\n",
      "\n",
      "[28899 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "\n",
    "def get_frame_similarity(frame1, frame2):\n",
    "    \"\"\"\n",
    "    Use the CLIP model to calculate semantic similarity between two frames.\n",
    "    \"\"\"\n",
    "    frame1 = preprocess(Image.fromarray(frame1)).unsqueeze(0).to(device)\n",
    "    frame2 = preprocess(Image.fromarray(frame2)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features1 = model.encode_image(frame1)\n",
    "        features2 = model.encode_image(frame2)\n",
    "    return torch.cosine_similarity(features1, features2).item()\n",
    "\n",
    "def find_cut_point(video_path, similarity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Apply a binary search method to find the transition points of semantic changes in the video and return the results by frame number.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    \n",
    "    ret, base_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"Failed to read the video: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    start_frame = 0\n",
    "    end_frame = total_frames - 1\n",
    "    cut_frame = None\n",
    "\n",
    "    while start_frame <= end_frame:\n",
    "        mid_frame = (start_frame + end_frame) // 2\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, mid_frame)\n",
    "        ret, mid_frame_img = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        similarity = get_frame_similarity(base_frame, mid_frame_img)\n",
    "        \n",
    "\n",
    "        if similarity < similarity_threshold:\n",
    "            cut_frame = mid_frame  \n",
    "            end_frame = mid_frame - 1  \n",
    "        else:\n",
    "            start_frame = mid_frame + 1  \n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    \n",
    "    if cut_frame is None:\n",
    "        cut_frame = 0\n",
    "        has_problem = True\n",
    "    else:\n",
    "        has_problem = False\n",
    "\n",
    "    return cut_frame, has_problem\n",
    "\n",
    "def process_videos_in_directory(directory, similarity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Iterate through all videos in the specified directory, find the segmentation points, and save them to a DataFrame\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    video_files = [f for f in os.listdir(directory) if f.endswith(\".mp4\")]\n",
    "\n",
    "    \n",
    "    for filename in tqdm(video_files, desc=\"Processing Videos\"):\n",
    "        video_path = os.path.join(directory, filename)\n",
    "\n",
    "        \n",
    "        cut_frame, has_problem = find_cut_point(video_path, similarity_threshold)\n",
    "\n",
    "        \n",
    "        results.append({\n",
    "            \"video_name\": filename,\n",
    "            \"cut_frame\": cut_frame,\n",
    "            \"has_problem\": has_problem\n",
    "        })\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_directory = \"./icable Reporter Videos\"\n",
    "    similarity_threshold = 0.85\n",
    "\n",
    "    \n",
    "    df = process_videos_in_directory(video_directory, similarity_threshold)\n",
    "\n",
    "    \n",
    "    output_path = \"./cut_points.pkl\"\n",
    "    df.to_pickle(output_path)\n",
    "\n",
    "    print(f\"Processing completed. Results have been saved to: {output_path}\")\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14303f-d43d-43ed-97f2-205b60642876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
