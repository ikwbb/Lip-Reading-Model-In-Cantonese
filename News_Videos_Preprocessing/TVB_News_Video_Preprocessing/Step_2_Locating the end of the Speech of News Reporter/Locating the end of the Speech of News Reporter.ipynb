{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d59d9a9",
   "metadata": {},
   "source": [
    "# Locating the end of the News Reporter's Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce12f6a",
   "metadata": {},
   "source": [
    "This Jupyter Notebook implements a video processing pipeline to detect semantic transition points (cut points) in videos using the CLIP (Contrastive Language-Image Pretraining) model. It processes a directory of videos, identifies the first frame where its semantic is largely different from the first frame, and saves the results to a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50512a2-73f8-4c08-bd06-586df1c3c4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos: 100%|██████████| 108050/108050 [30:45:23<00:00,  1.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed. Results have been saved to: ./TVB Reporter Videos/cut_points.pkl\n",
      "                          video_name  cut_frame  has_problem\n",
      "0       59654a72e6038331360802e0.mp4        235        False\n",
      "1       59655ff4e603831f360802e1.mp4        151        False\n",
      "2       596566e7c5e16c5133bc8476.mp4        153        False\n",
      "3       59656decc5e16c4d33bc8475.mp4        299        False\n",
      "4       59656ed0c5e16c5433bc8475.mp4        170        False\n",
      "...                              ...        ...          ...\n",
      "108045  678cc14d591bed663d6f86ac.mp4        231        False\n",
      "108046  678ccd28591bed663d6fe2c2.mp4        669        False\n",
      "108047  678cd118591bed663d6ffc9e.mp4        999        False\n",
      "108048  678cd46e591bed663d7014d5.mp4        546        False\n",
      "108049  678cd7a1591bed663d702db4.mp4        400        False\n",
      "\n",
      "[108050 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\", device=device)\n",
    "\n",
    "def get_frame_similarity(frame1, frame2):\n",
    "    \"\"\"\n",
    "    Use the CLIP model to calculate semantic similarity between two frames.\n",
    "    \"\"\"\n",
    "    frame1 = preprocess(Image.fromarray(frame1)).unsqueeze(0).to(device)\n",
    "    frame2 = preprocess(Image.fromarray(frame2)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features1 = model.encode_image(frame1)\n",
    "        features2 = model.encode_image(frame2)\n",
    "    return torch.cosine_similarity(features1, features2).item()\n",
    "\n",
    "def find_cut_point(video_path, similarity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Apply a binary search method to find the transition points of semantic changes in the video and return the results by frame number.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    \n",
    "    ret, base_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"Failed to read the video: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    start_frame = 0\n",
    "    end_frame = total_frames - 1\n",
    "    cut_frame = None\n",
    "\n",
    "    while start_frame <= end_frame:\n",
    "        mid_frame = (start_frame + end_frame) // 2\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, mid_frame)\n",
    "        ret, mid_frame_img = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        similarity = get_frame_similarity(base_frame, mid_frame_img)\n",
    "        \n",
    "\n",
    "        if similarity < similarity_threshold:\n",
    "            cut_frame = mid_frame  \n",
    "            end_frame = mid_frame - 1  \n",
    "        else:\n",
    "            start_frame = mid_frame + 1  \n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    \n",
    "    if cut_frame is None:\n",
    "        cut_frame = 0\n",
    "        has_problem = True\n",
    "    else:\n",
    "        has_problem = False\n",
    "\n",
    "    return cut_frame, has_problem\n",
    "\n",
    "def process_videos_in_directory(directory, similarity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Iterate through all videos in the specified directory, find the segmentation points, and save them to a DataFrame\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    video_files = [f for f in os.listdir(directory) if f.endswith(\".mp4\")]\n",
    "\n",
    "    \n",
    "    for filename in tqdm(video_files, desc=\"Processing Videos\"):\n",
    "        video_path = os.path.join(directory, filename)\n",
    "\n",
    "        \n",
    "        cut_frame, has_problem = find_cut_point(video_path, similarity_threshold)\n",
    "\n",
    "        \n",
    "        results.append({\n",
    "            \"video_name\": filename,\n",
    "            \"cut_frame\": cut_frame,\n",
    "            \"has_problem\": has_problem\n",
    "        })\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_directory = \"./TVB Reporter Videos\"\n",
    "    similarity_threshold = 0.85\n",
    "\n",
    "    \n",
    "    df = process_videos_in_directory(video_directory, similarity_threshold)\n",
    "\n",
    "    \n",
    "    output_path = os.path.join(video_directory, \"cut_points.pkl\")\n",
    "    df.to_pickle(output_path)\n",
    "\n",
    "    print(f\"Processing completed. Results have been saved to: {output_path}\")\n",
    "    print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
